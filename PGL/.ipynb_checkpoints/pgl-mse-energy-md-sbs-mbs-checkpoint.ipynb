{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-03T16:56:13.724120Z",
     "iopub.status.busy": "2023-08-03T16:56:13.723687Z",
     "iopub.status.idle": "2023-08-03T16:56:13.736508Z",
     "shell.execute_reply": "2023-08-03T16:56:13.734727Z",
     "shell.execute_reply.started": "2023-08-03T16:56:13.724080Z"
    }
   },
   "outputs": [],
   "source": [
    "M = 5 #[m for m in range(1,20)]\n",
    "J = 3\n",
    "K = 3\n",
    "d_mj = 50 #[d for d in range(50,100)]\n",
    "\n",
    "\n",
    "Fm = 1.0*1e9\n",
    "Fj = 5.0*1e9\n",
    "f0 = 5.0*1e9\n",
    "\n",
    "\n",
    "E_m = 3.6\n",
    "\n",
    "S_m = 0.8*(1e-25)\n",
    "S_j = 1.05*(1e-27)\n",
    "\n",
    "I_mk = 0.8\n",
    "\n",
    "alpha_mk = 75\n",
    "\n",
    "beta_1,beta_2 = 1,0.2\n",
    "beta_3,beta_4 = 1,0.2\n",
    "\n",
    "W_uj,W_dj = 15,15\n",
    "\n",
    "h1,h2 = 0.98,0.98\n",
    "\n",
    "G_0 = 1.6 * (1e-11)\n",
    "\n",
    "v = 4\n",
    "\n",
    "P_Fjt = 0.25\n",
    "P_mr = P_m0 = 0.5\n",
    "P_mt = 0.1\n",
    "P_theta1 = P_theta2 = 0.001\n",
    "\n",
    "rho = 18\n",
    "\n",
    "r0 = 1\n",
    "\n",
    "e0 = 1\n",
    "\n",
    "T_mstar = 4\n",
    "\n",
    "A_1j = 2e10\n",
    "A_2j = 4e10\n",
    "G_1j = 2*1e3\n",
    "G_2j = 4*1e3\n",
    "\n",
    "X_mk = 75\n",
    "\n",
    "\n",
    "E_m = 4.5\n",
    "E_j = 15\n",
    "E_0 = 30\n",
    "\n",
    "N = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T17:34:57.584629Z",
     "iopub.status.busy": "2023-08-03T17:34:57.584243Z",
     "iopub.status.idle": "2023-08-03T17:34:57.595912Z",
     "shell.execute_reply": "2023-08-03T17:34:57.594692Z",
     "shell.execute_reply.started": "2023-08-03T17:34:57.584597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6181202883595408,\n",
       " 0.44582682759656356,\n",
       " 0.41885188344001667,\n",
       " 0.725314288420496,\n",
       " 0.20725266051931168,\n",
       " 0.8726870104065173,\n",
       " 0.5054058663937231,\n",
       " 0.7964288520524295,\n",
       " 0.21692224666144966,\n",
       " 0.28587097475155565,\n",
       " 0.06505311141497994,\n",
       " 0.45923333540797096,\n",
       " 0.4216078351945074,\n",
       " 0.09191199150100593,\n",
       " 0.9896078879597027,\n",
       " 0.8376027250872685,\n",
       " 0.9836135084295317,\n",
       " 0.6389107188477442,\n",
       " 0.6342519626896961,\n",
       " 0.902460887142637,\n",
       " 0.22575486479024331,\n",
       " 0.43171293846798586,\n",
       " 0.7673201831645915,\n",
       " 0.880056194842702,\n",
       " 0.11689852162963943,\n",
       " 0.018655913022602277,\n",
       " 0.6020813837872281,\n",
       " 0.29796327410437684,\n",
       " 0.03703074205846735,\n",
       " 0.22146042983573722,\n",
       " 0.7610338029724503,\n",
       " 0.029023884890256646,\n",
       " 0.7038184880559014,\n",
       " 0.7637903501718589,\n",
       " 0.24177772730205993,\n",
       " 0.06195981812866791,\n",
       " 0.6164065468731508,\n",
       " 0.9566126107747135,\n",
       " 0.5889423270266003,\n",
       " 0.42985643223926306,\n",
       " 0.7191898189399389,\n",
       " 0.49011554806853164,\n",
       " 0.29905470425694003,\n",
       " 0.09437008609080633,\n",
       " 0.48956854556333473,\n",
       " 0.31211460436673066,\n",
       " 0.12870283254862191,\n",
       " 0.16588164006597272,\n",
       " 0.9894216501236005,\n",
       " 0.605295338702977,\n",
       " 0.8113315944232018,\n",
       " 0.8266918858083036,\n",
       " 0.8684205890604281,\n",
       " 0.8646685901837118,\n",
       " 0.14585046758688336,\n",
       " 0.6810342850941931,\n",
       " 0.45373909201083196,\n",
       " 0.8275332528881337,\n",
       " 0.6699964741181997,\n",
       " 0.15533260725789677,\n",
       " 0.3974970550528031,\n",
       " 0.052057024219696935,\n",
       " 0.3730181196411414,\n",
       " 0.9144382867670839,\n",
       " 0.9705393770547776,\n",
       " 0.10927787473351214,\n",
       " 0.627555744941959,\n",
       " 0.0362772207318921,\n",
       " 0.2581073676344966,\n",
       " 0.46331187558470943,\n",
       " 0.2632509775672638,\n",
       " 0.02037254636867125,\n",
       " 0.4598810871759361,\n",
       " 0.10114094325583478,\n",
       " 0.6581861844998592,\n",
       " 0.43804643263618326,\n",
       " 0.04933641133319899,\n",
       " 0.9951120072934889,\n",
       " 0.24832421453470954,\n",
       " 0.5549456243519525,\n",
       " 0.9271046856438617,\n",
       " 0.2540069763469063,\n",
       " 0.8517177608626594,\n",
       " 0.34301741857947843,\n",
       " 0.49064893907748186,\n",
       " 0.4566427347176534,\n",
       " 0.47725102532049835,\n",
       " 0.5547081922788906,\n",
       " 0.06431400702020773,\n",
       " 0.28526657583424964,\n",
       " 0.7332920119079389,\n",
       " 0.656058385384044,\n",
       " 0.8505370386734866,\n",
       " 0.8517010448549486,\n",
       " 0.22318246614954962,\n",
       " 0.42057477452867964,\n",
       " 0.20104913274149472,\n",
       " 0.6080238140462249,\n",
       " 0.7743338352546623,\n",
       " 0.7058499159817665]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.random.uniform(0,1) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T17:10:23.238720Z",
     "iopub.status.busy": "2023-08-03T17:10:23.238186Z",
     "iopub.status.idle": "2023-08-03T17:10:23.307890Z",
     "shell.execute_reply": "2023-08-03T17:10:23.306772Z",
     "shell.execute_reply.started": "2023-08-03T17:10:23.238680Z"
    }
   },
   "outputs": [],
   "source": [
    "def energy(po):\n",
    "#     print(po)\n",
    "    def cal_Em():\n",
    "        e = 0.0\n",
    "        for m in range(M):\n",
    "            for k in range(K):\n",
    "                lambda_mk1 = po[3][m][k]\n",
    "                f_mk = po[1][m][k]\n",
    "                e += S_m * I_mk * lambda_mk1 * alpha_mk * f_mk ** 2\n",
    "        return e\n",
    "\n",
    "    def cal_Rmj(m, j):\n",
    "        mu_mj = po[-1][m][j]\n",
    "        p_mt = po[-2][m]\n",
    "        R_mju = mu_mj * W_uj * np.log(1 + (p_mt * np.float_power(d_mj, -v) * (h1 ** 2)) / G_0)\n",
    "        R_mjd = mu_mj * W_dj * np.log(1 + (P_Fjt * np.float_power(d_mj, -v) * (h2 ** 2)) / G_0)\n",
    "        return R_mju, R_mjd\n",
    "\n",
    "    def cal_Fai_mj(m, j):\n",
    "        fai_mj1 = 0.0\n",
    "        fai_mj2 = 0.0\n",
    "\n",
    "        for k in range(K):\n",
    "            mu_mj = po[-1][m][j]\n",
    "            p_mt = po[-2][m]\n",
    "            lambda_mk2 = po[4][m][k]\n",
    "            lambda_mk3 = po[5][m][k]\n",
    "            R_mju, R_mjd = cal_Rmj(m, j)\n",
    "            uplink_fai = (P_m0 + rho * mu_mj * p_mt) * (beta_1 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mju\n",
    "            downlink_fai = (P_mr * beta_2 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mjd\n",
    "\n",
    "            fai_mj1 += (uplink_fai + downlink_fai)\n",
    "\n",
    "            f_mjk = po[2][m][j][k]\n",
    "            fai_mj2 += S_j * I_mk * lambda_mk2 * alpha_mk * (f_mjk ** 2)\n",
    "\n",
    "        return fai_mj1 + fai_mj2\n",
    "\n",
    "    def cal_Emj():\n",
    "\n",
    "        def cal_fai_m0(m):\n",
    "            fai_m0 = 0.0\n",
    "            for k in range(K):\n",
    "                lambda_mk3 = po[5][m][k]\n",
    "                uplink_fai = (P_theta1 * beta_3 * lambda_mk3 * I_mk) / r0\n",
    "                downlinke_fai = (P_theta2 * beta_4 * lambda_mk3 * I_mk) / r0\n",
    "                execute_fai = I_mk * lambda_mk3 * alpha_mk * e0\n",
    "\n",
    "                fai_m0 += (uplink_fai + downlinke_fai + execute_fai)\n",
    "\n",
    "            return fai_m0\n",
    "\n",
    "        total = 0.0\n",
    "        for m in range(M):\n",
    "            for j in range(J):\n",
    "                x_mj = po[0][m][j]\n",
    "                fai_mj = cal_Fai_mj(m, j)\n",
    "                fai_m0 = cal_fai_m0(m)\n",
    "                E_mj = (fai_mj + fai_m0)\n",
    "                total += x_mj * E_mj\n",
    "\n",
    "        return total\n",
    "\n",
    "    optim = cal_Em() + cal_Emj()\n",
    "#     print(cal_Em(),cal_Emj())\n",
    "    return optim\n",
    "\n",
    "\n",
    "def optim_score(po):\n",
    "    def cal_Em():\n",
    "        e = 0.0\n",
    "        for m in range(M):\n",
    "            for k in range(K):\n",
    "                lambda_mk1 = po[3][m][k]\n",
    "                f_mk = po[1][m][k]\n",
    "                e += S_m * I_mk * lambda_mk1 * alpha_mk * f_mk ** 2\n",
    "        return e\n",
    "\n",
    "    def cal_Rmj(m, j):\n",
    "        mu_mj = po[-1][m][j]\n",
    "        p_mt = po[-2][m]\n",
    "        R_mju = mu_mj * W_uj * np.log(1 + (p_mt * np.float_power(d_mj, -v) * (h1 ** 2)) / G_0)\n",
    "        R_mjd = mu_mj * W_dj * np.log(1 + (P_Fjt * np.float_power(d_mj, -v) * (h2 ** 2)) / G_0)\n",
    "        return R_mju, R_mjd\n",
    "\n",
    "    def cal_Fai_mj(m, j):\n",
    "        fai_mj1 = 0.0\n",
    "        fai_mj2 = 0.0\n",
    "\n",
    "        for k in range(K):\n",
    "            mu_mj = po[-1][m][j]\n",
    "            p_mt = po[-2][m]\n",
    "            lambda_mk2 = po[4][m][k]\n",
    "            lambda_mk3 = po[5][m][k]\n",
    "            R_mju, R_mjd = cal_Rmj(m, j)\n",
    "            uplink_fai = (P_m0 + rho * mu_mj * p_mt) * (beta_1 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mju\n",
    "            downlink_fai = (P_mr * beta_2 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mjd\n",
    "\n",
    "            fai_mj1 += (uplink_fai + downlink_fai)\n",
    "\n",
    "            f_mjk = po[2][m][j][k]\n",
    "            fai_mj2 += S_j * I_mk * lambda_mk2 * alpha_mk * (f_mjk ** 2)\n",
    "\n",
    "        return fai_mj1 + fai_mj2\n",
    "\n",
    "    def cal_Emj():\n",
    "\n",
    "        def cal_fai_m0(m):\n",
    "            fai_m0 = 0.0\n",
    "            for k in range(K):\n",
    "                lambda_mk3 = po[5][m][k]\n",
    "                uplink_fai = (P_theta1 * beta_3 * lambda_mk3 * I_mk) / r0\n",
    "                downlinke_fai = (P_theta2 * beta_4 * lambda_mk3 * I_mk) / r0\n",
    "                execute_fai = I_mk * lambda_mk3 * alpha_mk * e0\n",
    "\n",
    "                fai_m0 += (uplink_fai + downlinke_fai + execute_fai)\n",
    "\n",
    "            return fai_m0\n",
    "\n",
    "        total = 0.0\n",
    "        for m in range(M):\n",
    "            for j in range(J):\n",
    "                x_mj = po[0][m][j]\n",
    "                fai_mj = cal_Fai_mj(m, j)\n",
    "                fai_m0 = cal_fai_m0(m)\n",
    "                E_mj = (fai_mj + fai_m0)\n",
    "                total += x_mj * E_mj\n",
    "\n",
    "        return total\n",
    "\n",
    "    def penalty():\n",
    "\n",
    "        def time_constrain():\n",
    "            def cal_Tmjk(m, k):\n",
    "                lambda_mk2 = po[4][m][k]\n",
    "                lambda_mk3 = po[5][m][k]\n",
    "                total_time = 0.0\n",
    "                for j in range(J):\n",
    "                    x_mj = po[0][m][j]\n",
    "                    R_mju, R_mjd = cal_Rmj(m, j)\n",
    "                    f_mjk = po[2][m][j][k]\n",
    "                    sbs_uplink = (beta_1 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mju\n",
    "                    sbs_exe = (lambda_mk2 * I_mk * alpha_mk) / f_mjk\n",
    "                    sbs_downlink = (beta_2 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mjd\n",
    "                    sbs_time = (sbs_uplink + sbs_exe + sbs_downlink)\n",
    "\n",
    "                    mbs_uplink = (beta_3 * lambda_mk3 * I_mk) / r0\n",
    "                    mbs_exe = (lambda_mk3 * I_mk * alpha_mk) / f0\n",
    "                    mbs_downlink = (beta_4 * lambda_mk3 * I_mk) / r0\n",
    "                    mbs_time = (mbs_uplink + mbs_exe + mbs_downlink)\n",
    "\n",
    "                    total_time += (x_mj * (sbs_time + mbs_time))\n",
    "                return total_time\n",
    "\n",
    "            T_diff = []\n",
    "            for m in range(M):\n",
    "                tm = 0\n",
    "                for k in range(K):\n",
    "                    lambda_mk1 = po[3][m][k]\n",
    "                    f_mk = po[1][m][k]\n",
    "                    T_mk = (I_mk * lambda_mk1 * alpha_mk) / f_mk\n",
    "                    T_mkj = cal_Tmjk(m, k)\n",
    "                    tm += max(T_mk, T_mkj)\n",
    "                T_diff.append(max(0, tm - T_mstar))\n",
    "\n",
    "            return (np.array(T_diff) ** 2).sum()\n",
    "\n",
    "        def lambda_constrain():\n",
    "            lambda_diff = []\n",
    "            for m in range(M):\n",
    "                for k in range(K):\n",
    "                    lambda_mk1 = po[3][m][k]\n",
    "                    lambda_mk2 = po[4][m][k]\n",
    "                    lambda_mk3 = po[5][m][k]\n",
    "                    diff = lambda_mk1 + lambda_mk2 + lambda_mk3 - 1\n",
    "                    lambda_diff.append(diff)\n",
    "            return (np.array(lambda_diff) ** 2).sum()\n",
    "\n",
    "        def x_mj_constrain():\n",
    "            x_sum_diff = []\n",
    "            for m in range(M):\n",
    "                sum = 0\n",
    "                for j in range(J):\n",
    "                    sum += po[0][m][j]\n",
    "                diff = sum - 1\n",
    "                x_sum_diff.append(diff)\n",
    "            return (np.array(x_sum_diff) ** 2).sum()\n",
    "\n",
    "        def sbs_constrain():\n",
    "            cpu_diff = []\n",
    "            mem_diff = []\n",
    "            for j in range(J):\n",
    "                cpu_cycles = 0\n",
    "                mem = 0\n",
    "                for m in range(M):\n",
    "                    x_mj = po[0][m][j]\n",
    "                    for k in range(K):\n",
    "                        lambda_mk2 = po[4][m][k]\n",
    "                        cpu_cycles += x_mj * I_mk * lambda_mk2 * alpha_mk\n",
    "                        mem += x_mj * lambda_mk2 * I_mk * X_mk\n",
    "                cpu_diff.append(max(0, cpu_cycles - A_1j))\n",
    "                mem_diff.append(max(0, mem - G_1j))\n",
    "            return (np.array(cpu_diff) ** 2).sum() + (np.array(mem_diff) ** 2).sum()\n",
    "\n",
    "        def mbs_constrain():\n",
    "            cpu_diff = 0.0\n",
    "            mem_diff = 0.0\n",
    "            mem = 0\n",
    "            cpu = 0\n",
    "            for m in range(M):\n",
    "                for k in range(K):\n",
    "                    lambda_mk3 = po[5][m][k]\n",
    "                    cpu += I_mk * lambda_mk3 * alpha_mk\n",
    "                    mem += I_mk * lambda_mk3 * X_mk\n",
    "\n",
    "            cpu_diff = max(0, cpu - A_2j)\n",
    "            mem_diff = max(0, mem - G_2j)\n",
    "            return cpu_diff ** 2 + mem_diff ** 2\n",
    "\n",
    "        def energy_constrain():\n",
    "            def MDs_energy():\n",
    "                e_diff = []\n",
    "                for m in range(M):\n",
    "                    e = 0\n",
    "                    for k in range(K):\n",
    "                        lambda_mk1 = po[3][m][k]\n",
    "                        f_mk = po[1][m][k]\n",
    "                        e += S_m * I_mk * lambda_mk1 * alpha_mk * (f_mk ** 2)\n",
    "                    e_diff.append(max(0, e - E_m))\n",
    "                return (np.array(e_diff) ** 2).sum()\n",
    "\n",
    "            def SBSs_engry():\n",
    "                e_diff = []\n",
    "                for j in range(J):\n",
    "                    e = 0\n",
    "                    for m in range(M):\n",
    "                        x_mj = po[0][m][j]\n",
    "                        fai_mj = cal_Fai_mj(m, j)\n",
    "                        e += x_mj * fai_mj\n",
    "                    e_diff.append(max(0, e - E_j))\n",
    "                return (np.array(e_diff) ** 2).sum()\n",
    "\n",
    "            def MBS_engry():\n",
    "                e_diff = 0.0\n",
    "                e = 0\n",
    "                for m in range(M):\n",
    "                    for k in range(K):\n",
    "                        lambda_mk3 = po[5][m][k]\n",
    "                        uplink_e = (P_theta1 * beta_3 * lambda_mk3 * I_mk) / r0\n",
    "                        downlink_e = (P_theta2 * beta_4 * lambda_mk3 * I_mk) / r0\n",
    "                        exe_e = I_mk * lambda_mk3 * alpha_mk * e0\n",
    "                        e += (uplink_e + downlink_e + exe_e)\n",
    "                e_diff = max(0, e - E_0)\n",
    "                return e_diff ** 2\n",
    "\n",
    "            return MDs_energy() + SBSs_engry() + MBS_engry()\n",
    "\n",
    "        def x_mu_constrain():\n",
    "            x_mu_diff = []\n",
    "            mu_min_diff = []\n",
    "            mu_max_diff = []\n",
    "            for j in range(J):\n",
    "                sum = 0\n",
    "                for m in range(M):\n",
    "                    x_mj = po[0][m][j]\n",
    "                    mu_mj = po[-1][m][j]\n",
    "                    sum += x_mj * mu_mj\n",
    "                    mu_min_diff.append(max(0, -mu_mj))\n",
    "                    mu_max_diff.append(max(0, mu_mj - 1))\n",
    "                x_mu_diff.append(sum - 1)\n",
    "            return (np.array(x_mu_diff) ** 2).sum()\n",
    "\n",
    "        def pt_constrain():\n",
    "            pt_diff = []\n",
    "            for m in range(M):\n",
    "                pt = po[-2][m]\n",
    "                pt_diff.append(max(0, pt - P_mt))\n",
    "            return (np.array(pt_diff) ** 2).sum()\n",
    "\n",
    "        def fm_constrain():\n",
    "            fm_diff = []\n",
    "            for m in range(M):\n",
    "                fm = 0\n",
    "                for k in range(K):\n",
    "                    f_mk = po[1][m][k]\n",
    "                    fm += f_mk\n",
    "                fm_diff.append(max(0, fm - Fm))\n",
    "            return (np.array(fm_diff) ** 2).sum()\n",
    "\n",
    "        def fmj_constrain():\n",
    "            fmj_diff = []\n",
    "            for j in range(J):\n",
    "                fmj = 0\n",
    "                for m in range(M):\n",
    "                    x_mj = po[0][m][j]\n",
    "                    for k in range(K):\n",
    "                        f_mjk = po[2][m][j][k]\n",
    "                        fmj += f_mjk\n",
    "                fmj_diff.append(max(0, fmj - Fj))\n",
    "            return (np.array(fmj_diff) ** 2).sum()\n",
    "\n",
    "        total_penalty = time_constrain() + \\\n",
    "                        lambda_constrain() + \\\n",
    "                        x_mj_constrain() + \\\n",
    "                        sbs_constrain() + \\\n",
    "                        mbs_constrain() + \\\n",
    "                        energy_constrain() + \\\n",
    "                        x_mu_constrain() + \\\n",
    "                        pt_constrain() + \\\n",
    "                        fm_constrain() + \\\n",
    "                        fmj_constrain()\n",
    "        return total_penalty\n",
    "\n",
    "    optim = cal_Em() + cal_Emj() + N * penalty()\n",
    "\n",
    "    return optim\n",
    "\n",
    "\n",
    "class Individual:\n",
    "    def __init__(self, vector,D):\n",
    "        self.vector = vector\n",
    "        self.fitness_score = optim_score(vector)\n",
    "        self.p_best = vector\n",
    "        self.p_best_score = self.fitness_score\n",
    "        self.N = N\n",
    "        self.D = D\n",
    "        self.velocity = np.zeros(self.D)\n",
    "\n",
    "        self.exemplar_vector = None\n",
    "        self.exemplar_score = None\n",
    "\n",
    "    # def update(self):\n",
    "        # self.fitness_score = optim_score(self.vector)\n",
    "        # if self.fitness_score < self.p_best_score:\n",
    "        #     self.p_best_score = self.fitness_score\n",
    "        #     self.p_best = self.vector\n",
    "        #     self.exemplar_vector =\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T17:52:04.130152Z",
     "iopub.status.busy": "2023-08-03T17:52:04.129520Z",
     "iopub.status.idle": "2023-08-03T18:06:26.776341Z",
     "shell.execute_reply": "2023-08-03T18:06:26.774588Z",
     "shell.execute_reply.started": "2023-08-03T17:52:04.130099Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3764549744.py:93: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  temp_list.append(np.long(np.random.choice(2)))\n",
      "/tmp/ipykernel_32/1280734304.py:82: RuntimeWarning: invalid value encountered in log\n",
      "  R_mju = mu_mj * W_uj * np.log(1 + (p_mt * np.float_power(d_mj, -v) * (h1 ** 2)) / G_0)\n",
      "/tmp/ipykernel_32/1280734304.py:96: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  uplink_fai = (P_m0 + rho * mu_mj * p_mt) * (beta_1 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mju\n",
      "/tmp/ipykernel_32/1280734304.py:97: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  downlink_fai = (P_mr * beta_2 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mjd\n",
      "/tmp/ipykernel_32/1280734304.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  total += x_mj * E_mj\n",
      "/tmp/ipykernel_32/1280734304.py:142: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sbs_uplink = (beta_1 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mju\n",
      "/tmp/ipykernel_32/1280734304.py:144: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sbs_downlink = (beta_2 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mjd\n",
      "/tmp/ipykernel_32/1280734304.py:152: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  total_time += (x_mj * (sbs_time + mbs_time))\n",
      "/tmp/ipykernel_32/1280734304.py:143: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sbs_exe = (lambda_mk2 * I_mk * alpha_mk) / f_mjk\n",
      "/tmp/ipykernel_32/1280734304.py:143: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sbs_exe = (lambda_mk2 * I_mk * alpha_mk) / f_mjk\n",
      "/tmp/ipykernel_32/1280734304.py:161: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  T_mk = (I_mk * lambda_mk1 * alpha_mk) / f_mk\n",
      "/tmp/ipykernel_32/1280734304.py:239: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e += x_mj * fai_mj\n",
      "/tmp/ipykernel_32/1280734304.py:29: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  uplink_fai = (P_m0 + rho * mu_mj * p_mt) * (beta_1 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mju\n",
      "/tmp/ipykernel_32/1280734304.py:30: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  downlink_fai = (P_mr * beta_2 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mjd\n",
      "/tmp/ipykernel_32/1280734304.py:60: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  total += x_mj * E_mj\n",
      "/tmp/ipykernel_32/1280734304.py:96: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  uplink_fai = (P_m0 + rho * mu_mj * p_mt) * (beta_1 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mju\n",
      "/tmp/ipykernel_32/1280734304.py:97: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  downlink_fai = (P_mr * beta_2 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mjd\n",
      "/tmp/ipykernel_32/1280734304.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  T_mk = (I_mk * lambda_mk1 * alpha_mk) / f_mk\n",
      "/tmp/ipykernel_32/1280734304.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sbs_uplink = (beta_1 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mju\n",
      "/tmp/ipykernel_32/1280734304.py:144: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sbs_downlink = (beta_2 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mjd\n",
      "/tmp/ipykernel_32/1280734304.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  uplink_fai = (P_m0 + rho * mu_mj * p_mt) * (beta_1 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mju\n",
      "/tmp/ipykernel_32/1280734304.py:30: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  downlink_fai = (P_mr * beta_2 * (lambda_mk2 + lambda_mk3) * I_mk) / R_mjd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score:  1.6450370503517412e+31 best_e:  311.8080149731133 iter avg:  nan\n",
      "best_score:  1.6450370503517412e+31 best_e:  311.8080149731133 iter avg:  nan\n",
      "best_score:  1.4948346808098742e+31 best_e:  300.8814196091629 iter avg:  nan\n",
      "best_score:  1.4948346808098742e+31 best_e:  300.8814196091629 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  8.153821790155806e+30 best_e:  296.00101904725227 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  6.23650402844217e+30 best_e:  96.25091496742643 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  4.401325253465734e+30 best_e:  53.30419299484628 iter avg:  nan\n",
      "best_score:  3.6795513019850275e+30 best_e:  74.33056283277296 iter avg:  nan\n",
      "best_score:  1.365885748025138e+30 best_e:  38.05955385617972 iter avg:  nan\n",
      "best_score:  1.365885748025138e+30 best_e:  38.05955385617972 iter avg:  nan\n",
      "best_score:  1.365885748025138e+30 best_e:  38.05955385617972 iter avg:  nan\n",
      "best_score:  1.365885748025138e+30 best_e:  38.05955385617972 iter avg:  nan\n",
      "best_score:  1.365885748025138e+30 best_e:  38.05955385617972 iter avg:  nan\n",
      "best_score:  1.365885748025138e+30 best_e:  38.05955385617972 iter avg:  nan\n",
      "best_score:  1.365885748025138e+30 best_e:  38.05955385617972 iter avg:  nan\n",
      "best_score:  1.0651908653316737e+30 best_e:  35.36554093123184 iter avg:  nan\n",
      "best_score:  1.0651908653316737e+30 best_e:  35.36554093123184 iter avg:  nan\n",
      "best_score:  1.0651908653316737e+30 best_e:  35.36554093123184 iter avg:  nan\n",
      "best_score:  1.0651908653316737e+30 best_e:  35.36554093123184 iter avg:  nan\n",
      "best_score:  1.0651908653316737e+30 best_e:  35.36554093123184 iter avg:  nan\n",
      "best_score:  1.0651908653316737e+30 best_e:  35.36554093123184 iter avg:  nan\n",
      "best_score:  1.0651908653316737e+30 best_e:  35.36554093123184 iter avg:  nan\n",
      "best_score:  1.0651908653316737e+30 best_e:  35.36554093123184 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  1.0148318056930945e+30 best_e:  107.74368983815356 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  8.685770691021287e+29 best_e:  40.264020976904035 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n",
      "best_score:  7.895931724633762e+29 best_e:  27.80664161898746 iter avg:  nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 253\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    252\u001b[0m     pgl \u001b[38;5;241m=\u001b[39m PGL(\u001b[38;5;241m0.05\u001b[39m,\u001b[38;5;241m1.49618\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m500\u001b[39m,\u001b[38;5;241m0.95\u001b[39m,\u001b[38;5;241m0.4\u001b[39m,\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m--> 253\u001b[0m     \u001b[43mpgl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m#     prob,c,c1,c2,max_iters,w_u,w_b,nums\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 231\u001b[0m, in \u001b[0;36mPGL.optim\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD):\n\u001b[1;32m    230\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnums)]\n\u001b[0;32m--> 231\u001b[0m     \u001b[43mcrossover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo_each\u001b[49m\u001b[43m,\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43meach\u001b[49m\u001b[43m,\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     mutation(o_each,d)\n\u001b[1;32m    234\u001b[0m o_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten_package(o_each)\n",
      "Cell \u001b[0;32mIn[28], line 171\u001b[0m, in \u001b[0;36mPGL.optim.<locals>.crossover\u001b[0;34m(o, other, each, d)\u001b[0m\n\u001b[1;32m    169\u001b[0m     o[d] \u001b[38;5;241m=\u001b[39m rd \u001b[38;5;241m*\u001b[39m pd[d] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m rd) \u001b[38;5;241m*\u001b[39m gd[d]\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     z_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_flatten(z)\n\u001b[1;32m    173\u001b[0m     o[d] \u001b[38;5;241m=\u001b[39m z_v[d]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/copy.py:128\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    124\u001b[0m     d[PyStringMap] \u001b[38;5;241m=\u001b[39m PyStringMap\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m d, t\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeepcopy\u001b[39m(x, memo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _nil\u001b[38;5;241m=\u001b[39m[]):\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deep copy operation on arbitrary Python objects.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    See the module's __doc__ string for more info.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from papper_sbs_mbs.parameters import *\n",
    "# from Individual import *\n",
    "import copy\n",
    "\n",
    "\n",
    "class PGL:\n",
    "    def __init__(self,prob,c,c1,c2,max_iters,w_u,w_b,nums):\n",
    "        self.prob = prob\n",
    "        self.c = c\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.max_iters = max_iters\n",
    "        self.w_u = w_u\n",
    "        self.w_b = w_b\n",
    "        self.nums = nums\n",
    "\n",
    "        self.segment = [M * J,M * K,M * K * J,M * K,M * K,M * K,M,M * J]\n",
    "        for i in range(1,len(self.segment)):\n",
    "            self.segment[i] += self.segment[i - 1]\n",
    "        # print(self.segment)\n",
    "\n",
    "\n",
    "        self.global_best = {\n",
    "            \"score\": None,\n",
    "            \"vector\": None\n",
    "        }\n",
    "\n",
    "        np.random.seed(3)\n",
    "        self.D = M * (4 * K + 2 * J + J * K + 1)\n",
    "\n",
    "        self.population = self.generate_populations()\n",
    "\n",
    "\n",
    "    def list_flatten(self,list):\n",
    "        v = np.zeros(0)\n",
    "        # print(v)\n",
    "        for each in list:\n",
    "            temp = each.reshape(-1)\n",
    "            v = np.append(v,temp)\n",
    "        v = np.array(v).reshape(-1)\n",
    "        # print(v.shape)\n",
    "        return v\n",
    "\n",
    "    def flatten_package(self,vector):\n",
    "        start = 0\n",
    "        # print(len(vector))\n",
    "        x_mj = vector[0:self.segment[0]].reshape(M,J)\n",
    "\n",
    "        f_mk = vector[self.segment[0]:self.segment[1]].reshape(M,K)\n",
    "        f_mjk = vector[self.segment[1]:self.segment[2]].reshape(M,J,K)\n",
    "        lambda_mk1 = vector[self.segment[2]:self.segment[3]].reshape(M,K)\n",
    "        lambda_mk2 = vector[self.segment[3]:self.segment[4]].reshape(M, K)\n",
    "        lambda_mk3 = vector[self.segment[4]:self.segment[5]].reshape(M, K)\n",
    "        p_mt = vector[self.segment[5]:self.segment[6]].reshape(M)\n",
    "        mu_mj = vector[self.segment[6]:self.segment[7]].reshape(M, J)\n",
    "        v = [x_mj.reshape(M, J),\n",
    "                  f_mk.reshape(M, K),\n",
    "                  f_mjk.reshape(M, J, K),\n",
    "                  lambda_mk1.reshape(M, K),\n",
    "                  lambda_mk2.reshape(M, K),\n",
    "                  lambda_mk3.reshape(M, K),\n",
    "                  p_mt,\n",
    "                  mu_mj.reshape(M, J)]\n",
    "        return v\n",
    "\n",
    "\n",
    "    def get_exeamplar(self,each):\n",
    "        # e_vector = copy.deepcopy(each.vector)\n",
    "        p_vector = copy.deepcopy(each.p_best)\n",
    "        g_vector = copy.deepcopy(self.global_best[\"vector\"])\n",
    "\n",
    "        pd = self.list_flatten(p_vector)\n",
    "        gd = self.list_flatten(g_vector)\n",
    "\n",
    "        r1 = np.random.randn()\n",
    "        r2 = np.random.randn()\n",
    "\n",
    "        e_vector = ((self.c1 * r1 * pd) + (self.c2 * r2 * gd)) / (self.c1 * r1 + self.c2 * r2)\n",
    "        return self.flatten_package(e_vector)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def generate_populations(self):\n",
    "        # pos = np.random.choice(1)\n",
    "        populations = []\n",
    "\n",
    "        def generate():\n",
    "            temp_list = []\n",
    "            for i in range(M * J):\n",
    "                temp_list.append(np.long(np.random.choice(2)))\n",
    "            x_mj = np.array(temp_list)\n",
    "            temp_list.clear()\n",
    "\n",
    "            for i in range(M * K):\n",
    "                temp_list.append(np.random.randint(Fm))\n",
    "            f_mk = np.array(temp_list)\n",
    "            temp_list.clear()\n",
    "\n",
    "            for i in range(M * K * J):\n",
    "                temp_list.append(np.random.randint(Fj))\n",
    "            f_mjk = np.array(temp_list)\n",
    "            temp_list.clear()\n",
    "\n",
    "\n",
    "            for i in range(M * K):\n",
    "                temp_list.append(np.random.uniform(0, 1))\n",
    "            lambda_mk1 = np.array(temp_list)\n",
    "            temp_list.clear()\n",
    "\n",
    "            for i in range(M * K):\n",
    "                temp_list.append(np.random.uniform(0, 1-lambda_mk1[i]))\n",
    "            lambda_mk2 = np.array(temp_list)\n",
    "            temp_list.clear()\n",
    "\n",
    "\n",
    "            lambda_mk3 = np.array(1 - lambda_mk1 - lambda_mk2)\n",
    "\n",
    "            for i in range(M):\n",
    "                temp_list.append(np.random.uniform(P_mt))\n",
    "            p_mt = np.array(temp_list)\n",
    "            temp_list.clear()\n",
    "\n",
    "            for i in range(M * J):\n",
    "                temp_list.append(np.random.uniform(0, 1))\n",
    "            mu_mj = np.array(temp_list)\n",
    "            temp_list.clear()\n",
    "\n",
    "            vector = [x_mj.reshape(M,J),\n",
    "                    f_mk.reshape(M,K),\n",
    "                    f_mjk.reshape(M,J,K),\n",
    "                    lambda_mk1.reshape(M,K),\n",
    "                    lambda_mk2.reshape(M,K),\n",
    "                    lambda_mk3.reshape(M,K),\n",
    "                    p_mt,\n",
    "                    mu_mj.reshape(M,J)]\n",
    "\n",
    "            return vector\n",
    "\n",
    "        for n in range(self.nums):\n",
    "            individual = Individual(generate(),self.D)\n",
    "            if self.global_best[\"score\"] == None  or individual.fitness_score < self.global_best[\"score\"]:\n",
    "                self.global_best[\"score\"] = individual.fitness_score\n",
    "                self.global_best[\"vector\"] = individual.vector\n",
    "            populations.append(individual)\n",
    "\n",
    "        for each in populations:\n",
    "            exemplar = self.get_exeamplar(each)\n",
    "            each.exemplar_vector = exemplar\n",
    "            each.exemplar_score = optim_score(exemplar)\n",
    "\n",
    "\n",
    "        return populations\n",
    "\n",
    "\n",
    "    def optim(self):\n",
    "\n",
    "        def crossover(o,other,each,d):\n",
    "            if each.fitness_score < other.fitness_score:\n",
    "                p_vector = copy.deepcopy(each.vector)\n",
    "                g_vector = copy.deepcopy(self.global_best[\"vector\"])\n",
    "                pd = self.list_flatten(p_vector)\n",
    "                gd = self.list_flatten(g_vector)\n",
    "\n",
    "                rd = np.random.uniform(0,1)\n",
    "                # print(len(o),len(pd),len(gd))\n",
    "                o[d] = rd * pd[d] + (1 - rd) * gd[d]\n",
    "            else:\n",
    "                z = copy.deepcopy(other.vector)\n",
    "                z_v = self.list_flatten(z)\n",
    "                o[d] = z_v[d]\n",
    "\n",
    "        def mutation(o,d):\n",
    "            rd = np.random.uniform()\n",
    "            if rd < self.prob:\n",
    "                if d < M*J:\n",
    "                    o[d] = np.random.randint(2)\n",
    "                elif d < M*J + M*K:\n",
    "                    o[d] = np.random.randint(0,Fm)\n",
    "                elif d < M*J + M*K + M*J*K:\n",
    "                    o[d] = np.random.randint(0,Fj)\n",
    "                elif d < M*J + M*K + M*J*K + 3*M*K:\n",
    "                    o[d] = np.random.uniform(0,1)\n",
    "                elif d < M*J + M*K + M*J*K + 3*M*K + M:\n",
    "                    o[d] = np.random.uniform(0,P_mt)\n",
    "                else:\n",
    "                    o[d] = np.random.uniform(0,1)\n",
    "\n",
    "\n",
    "        def update(each,candiate,w):\n",
    "            # print(candiate)\n",
    "            candiate_v = self.list_flatten(candiate)\n",
    "            each_v = self.list_flatten(each.vector)\n",
    "            rd = np.random.uniform(0,1)\n",
    "            v = w * each.velocity + self.c*rd*(candiate_v - each_v)\n",
    "            each_v += v\n",
    "            for d in range(len(each_v)):\n",
    "                if each_v[d] < 0:\n",
    "                    each_v[d] = 0\n",
    "                    v[d] = 0.1 * (-v[d])\n",
    "            each.velocity = v\n",
    "\n",
    "            each.vector = self.flatten_package(each_v)\n",
    "            each.fitness_score = optim_score(each.vector)\n",
    "#             print(each.vector)\n",
    "            if each.fitness_score < each.p_best_score:\n",
    "#                 print(each.vector[0])\n",
    "                each.p_best_score = each.fitness_score\n",
    "                each.p_best_vector = each.vector\n",
    "                each.exemplar = self.get_exeamplar(each)\n",
    "                each.exemplar_score = optim_score(each.exemplar)\n",
    "            if each.fitness_score < self.global_best[\"score\"]:\n",
    "                self.global_best[\"score\"] = each.fitness_score\n",
    "                self.global_best[\"vector\"] = each.vector\n",
    "            return energy(each.vector)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for iter in range(self.max_iters):\n",
    "            w = self.w_u - (iter * (self.w_u - self.w_b))/self.max_iters\n",
    "            avg = 0.0\n",
    "            for each in self.population:\n",
    "                o_each = self.list_flatten(copy.deepcopy(each.vector))\n",
    "\n",
    "                for d in range(self.D):\n",
    "                    other = self.population[np.random.choice(self.nums)]\n",
    "                    crossover(o_each,other,each,d)\n",
    "                    mutation(o_each,d)\n",
    "\n",
    "                o_vector = self.flatten_package(o_each)\n",
    "                candidate = None\n",
    "                if optim_score(o_vector) < each.exemplar_score:\n",
    "                    candidate = o_vector\n",
    "                else:\n",
    "                    candidate = each.exemplar_vector\n",
    "\n",
    "                avg += update(each,candidate,w)\n",
    "\n",
    "            best_e = energy(self.global_best[\"vector\"])\n",
    "            print(\"best_score: \",self.global_best[\"score\"],\"best_e: \",best_e,\"iter avg: \",avg/self.nums)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pgl = PGL(0.05,1.49618,0.5,0.5,500,0.95,0.4,100)\n",
    "    pgl.optim()\n",
    "#     prob,c,c1,c2,max_iters,w_u,w_b,nums\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
